{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to fit the input requirements of the model\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.1429 - accuracy: 0.9582 - val_loss: 0.0643 - val_accuracy: 0.9777\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0467 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0460 - val_accuracy: 0.9855\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0427 - val_accuracy: 0.9865\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0449 - val_accuracy: 0.9866\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0414 - val_accuracy: 0.9875\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0580 - val_accuracy: 0.9848\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0511 - val_accuracy: 0.9866\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0600 - val_accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0675 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a3b5652050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Convolutional Neural Network (CNN) using TensorFlow/Keras\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    "    # A convolutional layer with 32 filters of size 3×3.\n",
    "    # Uses ReLU activation to introduce non-linearity.\n",
    "    # input_shape=(28, 28, 1) specifies the 28×28 grayscale images.\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # A max pooling layer with a 2×2 filter to downsample feature maps, reducing spatial dimensions and computation.\n",
    "\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Converts the 2D feature maps into a 1D vector for input to the fully connected layers.\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    # A fully connected (dense) layer with 128 neurons and ReLU activation for learning high-level features.\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # The output layer with 10 neurons (one for each digit 0-9).\n",
    "    # Uses softmax activation to output class probabilities.\n",
    "    \n",
    "    Dense(10, activation='softmax')\n",
    "\n",
    "])\n",
    "# Uses Adam optimizer, which adapts learning rates dynamically for efficient training.\n",
    "# Since labels are integers (0-9), this loss function is used for multi-class classification.\n",
    "# Tracks accuracy as the evaluation metric.\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trains the model using the training data (X_train, y_train).\n",
    "# Runs for 10 epochs (full passes through the dataset).\n",
    "# Uses validation_data=(X_test, y_test) to track accuracy and loss on unseen test data.\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       1.00      0.97      0.98      1032\n",
      "           3       0.98      0.99      0.99      1010\n",
      "           4       0.96      0.99      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.98      0.98       958\n",
      "           7       0.98      0.99      0.99      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.98      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels (if necessary)\n",
    "if y_pred.ndim > 1 and y_pred.shape[1] > 1:  # Check if output is probabilistic\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Use metrics like accuracy and confusion matrices\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
